由於近日機器學習課程的office hour生意興隆，
實驗室門庭若市，人潮絡繹不絕，
助教決定把一些常見的問題透過公告先回答一輪。

1.test error比train error低是對的嗎?
大多數情況不會這樣，不過這次作業剛好發生了。
這組dataset剛剛好test data都可以fit很好。
如果希望可以看到比較合理的結果，可以對data做shuffle。
如果不想，那也可以在report中寫推測原因(dataset)

2.regularize term加上去效果不明顯(幾乎貼在一起)是對的嗎?
承上題，test error已經比train error低了，表示還沒發生overfitting的問題，
導致加regularize term就變得有點多餘、不必要，
所以效果不明顯是正常的。

3.誤差大概在8萬左右，感覺誤差有點大，這樣是對的嗎?
對，這告訴你不要拿了沒幾項數據出來預測房價或股市，
就想要精準預測跟賺錢，real world的task是很難的，
要考慮的東西太多。

4.如果我M變大，錯誤率衝上去，是正常的嗎?
不正常，至少training error只應該嚴格遞減，
因為你函數越複雜，fitting能力越好，錯誤率會越低，
如果你發生錯誤率變大的情況，未看先猜你的反矩陣誤差太大了。
你可以把pinv(A)換成A\eye(size(A))。

小常識:
inv是一般的反矩陣，但在行列式值趨近於0時會爆掉。
pinv是psuedo inverse，他是在原矩陣加了一個類似單位矩陣的東西，
讓他變成nonsingular，再inverse，但因為他加了單位矩陣上去，所以會導致誤差
\是用高斯消去法去求的，可以避免前面兩者造成的問題

5.M=1、2、3分別要有哪些term?
M=1就是f1(x)=w0+w1x1+w2x2+w3x3
M=2就是f2(x)=w0+w1x1+w2x2+w3x3+w4x1^2+w5x2^2+w6x3^2+w7^x1x2+w8x1x3+w9x2x3
M=3有20個term，自己類推

6.承上題，這些式子可以用迴圈得到嗎?
可以，至於要怎麼做自己想。

7.most contributive attribute怎麼求?
C3取2，任取兩個做regression，誤差最大的那個就表示你拿掉的attribute對預測很重要。

8.weight matrix怎麼求?
公式在第三章。

---以上內容由厲害的助教黃煜閔編輯---



